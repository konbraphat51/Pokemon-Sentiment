{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時期ごとの極性・共起変遷を追う"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なもの\n",
    "* ID, POPLATION_ID, PERIOD_IDのセット\n",
    "* local_stopwordsのセット\n",
    "* 分析したキーワードをKeywords/Timelapse/ID-from-POPULATION_ID.txtにスペース区切りで保存\n",
    "* get_time_index()の書き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"\"\n",
    "\n",
    "POPULATION_ID = \"\"\n",
    "\n",
    "PERIOD_ID = \"\"\n",
    "\n",
    "#分析対象の単語ファイル\n",
    "keywords_file = \"Keywords/Timelapse/%s-from-%s.txt\"%(ID, POPULATION_ID)\n",
    "\n",
    "#ストップワード抜きの形態素解析・極性分析完了したデータ\n",
    "without_stopwords_text_file = \"Progresses/NonStopword/%s-from-%s.txt\"%(ID, POPULATION_ID)\n",
    "\n",
    "##TFIDFモデル\n",
    "tfidf_model_file = \"Models/Tfidf/%s-from-%s.model\"%(ID, POPULATION_ID)\n",
    "\n",
    "#保存するファイル\n",
    "sentiment_timelapse_file = \"Sentiment/Timelapse/%s-from-%s-by-%s.txt\"%(ID, POPULATION_ID, PERIOD_ID)\n",
    "\n",
    "#内部的に品詞を区別する区切り文字\n",
    "TOKEN_DIVIDER = \"<334>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#共起キーワードのストップワード（ここだけ）\n",
    "local_stopwords = [\"br\", \"ミミッキュ\", \"ミミ\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与えられた時期にインデックスを割り振る\n",
    "分けたい時期にあわせて書き換える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#これを書き換える\n",
    "#万が一 -1 が出てしまうとエラーが出てしまうので注意（上限はない）\n",
    "def get_time_index(time: datetime):\n",
    "    #2000年から一年ごとに割り振る\n",
    "    if time == None:\n",
    "        return None\n",
    "\n",
    "    years_passed = time.year - 2000\n",
    "    \n",
    "    if years_passed >= 0:\n",
    "        return years_passed\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#保持しているデータの形式からdatetime型に変換\n",
    "def convert_time(text: str):\n",
    "    if (text == None) | (text == \"None\"):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.strptime(text, \"%Y/%m/%d|%H/%M/%S\")\n",
    "\n",
    "#最大インデックスを算出\n",
    "MAX_TIME_INDEX = get_time_index(datetime.now())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理済みデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_table(without_stopwords_text_file)\n",
    "\n",
    "df_main.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本ノート用キーワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(keywords_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    keywords = f.read().split()\n",
    "\n",
    "keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 母集団からのTFIDFモデルをサルベージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split(TOKEN_DIVIDER)\n",
    "\n",
    "with open(tfidf_model_file, \"rb\") as f:\n",
    "    tfidf_model = pickle.load(f)\n",
    "\n",
    "#対象（名詞・形容詞）を見せる用\n",
    "tfidf_model_showing = deepcopy(tfidf_model)\n",
    "tfidf_model_showing.ngram = (1,1)\n",
    "tfidf_model_showing.tokenizer = tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各テキストに時期インデックスを割り振る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "for _, row in df_main.iterrows():\n",
    "    indices.append(get_time_index(convert_time(row[\"date\"])))\n",
    "\n",
    "df_main[\"time_index\"] = indices\n",
    "\n",
    "df_main.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### キーワードごとに分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#キーワードごとに\n",
    "for keyword in keywords:\n",
    "    scores = []\n",
    "    coocs = []\n",
    "    counts = []\n",
    "\n",
    "    #時期インデックスごとに\n",
    "    for time_index in range(MAX_TIME_INDEX):\n",
    "        #極性スコア計算\n",
    "        score = 0\n",
    "        cnt = 0\n",
    "        texts = []\n",
    "        for _, row in df_main[df_main[\"time_index\"] == time_index].iterrows():\n",
    "            if keyword in row[\"disassembled_all\"].split(TOKEN_DIVIDER):\n",
    "                cnt += 1\n",
    "                if row[\"Sentiment\"] == \"pos\":\n",
    "                    score += 1\n",
    "                elif row[\"Sentiment\"] == \"neg\":\n",
    "                    score -= 1\n",
    "                texts.append(row[\"disassembled_target\"])\n",
    "        if cnt != 0:\n",
    "            score /= cnt\n",
    "        else:\n",
    "            score = 0\n",
    "        \n",
    "        ##共起\n",
    "        #TFIDF計算\n",
    "        if cnt != 0:\n",
    "            tfidf_spycy = tfidf_model_showing.transform(texts)\n",
    "            tfidf_df = pd.DataFrame(tfidf_spycy.toarray(), columns=tfidf_model_showing.get_feature_names_out())\n",
    "            tfidf_mean = tfidf_df.mean(axis=0)\n",
    "\n",
    "            #単語名と結び付け\n",
    "            tfidf_mean = tfidf_mean.sort_values(ascending=False)\n",
    "\n",
    "            #ストップワードの削除\n",
    "            for word in local_stopwords:\n",
    "                try:\n",
    "                    tfidf_mean = tfidf_mean.drop(word)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if len(tfidf_mean) > 1:\n",
    "                cooc = \", \".join(tfidf_mean[1:min(6, len(tfidf_mean))].index)\n",
    "            else:\n",
    "                cooc = \"\"\n",
    "        else:\n",
    "            cooc = \"\"\n",
    "        \n",
    "        scores.append(score)\n",
    "        coocs.append(cooc)\n",
    "        counts.append(cnt)\n",
    "\n",
    "    df_keyword = pd.DataFrame(list(zip(counts, scores, coocs)), columns=[\"Scores\", \"Counts\", \"CoOccure\"])\n",
    "\n",
    "    print(keyword)\n",
    "    print(df_keyword)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af19612f8f38f6812d87a5ef9419a460d9700d7e1cf8ff071cf581e2ee4d6233"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
